transformers>=4.40.0
datasets>=2.12.0
evaluate>=0.4.0
torch>=2.0.0
numpy>=1.24.0
scikit-learn>=1.2.2
accelerate>=0.20.3
sentencepiece>=0.1.98
tokenizers>=0.13.0
fastapi>=0.95.0
uvicorn>=0.22.0
python-multipart>=0.0.6
onnxruntime
optimum
sentencepiece
